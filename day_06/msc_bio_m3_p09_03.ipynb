{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs\n",
    "\n",
    "This is not so much as an execise, but rather a little example of producing a Gnerative Adverserial Network (GAN). \n",
    "Some of the code is a bit overly complicated, mainly because the output is saved as images. \n",
    "\n",
    "Overall, the GAN uses two parts - an generator and a discriminator. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Some imports for handling data, learning, and plotting\n",
    "\n",
    "Please ignore any warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import os,os.path\n",
    "from functools import reduce\n",
    "\n",
    "# Keras modules\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "\n",
    "import seaborn\n",
    "seaborn.set(style=\"ticks\", color_codes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The simple GAN object\n",
    "\n",
    "I encoded the method into a python class. Please note, that comments are sparse and I do appologise for it. \n",
    "For the sake of trying it out, please just accept the code as is. If you want to dive in, please let me know. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_gan():\n",
    "\n",
    "    def __init__(self, input_shape, output_shape, \n",
    "                 generator_input_dim,\n",
    "                 optimizer=None,\n",
    "                 metrics=['accuracy'],\n",
    "                 deep_generator_shape=[8,8]):\n",
    "\n",
    "        # check if optimizer has been supplied\n",
    "        if not optimizer:\n",
    "            # use default optimizer RMSProp\n",
    "            self.optimizer = RMSprop()\n",
    "        else:\n",
    "            self.optimser  = optimizer\n",
    "\n",
    "        self.metrics       = metrics\n",
    "        self.ploted        = None\n",
    "            \n",
    "        self.input_shape           = input_shape             # input shape of the original data\n",
    "        self.output_shape          = output_shape            # don't know yet\n",
    "        self.generator_input_dim   = generator_input_dim     # shape of random vector\n",
    "        self.deep_generator_shape  = deep_generator_shape\n",
    "        \n",
    "        # Build models\n",
    "        self.generator_model     = self.build_generator_model(deep_generator_shape=deep_generator_shape)\n",
    "        self.discriminator_model = self.build_discriminator_model()\n",
    "        self.gan                 = self.build_and_compile_gan()\n",
    "\n",
    "    # creates random samples using the generator part\n",
    "    def generate_samples(self,number_of_samples=500):\n",
    "        # generate artificial data\n",
    "        if self.generator_model:\n",
    "            random_vectors    = self.produce_random_vectors(number_of_samples)\n",
    "            genenerated_batch = self.generator_model.predict(random_vectors)\n",
    "            return genenerated_batch\n",
    "            # return self.transformer.inverse_transform(genenerated_batch)\n",
    "        return None\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self, epochs, train_data, batch_size, \n",
    "              visulisation={'image_folder':None,'number_randon_vector':500},\n",
    "              epoch_performance_display=10):\n",
    "\n",
    "        number_randon_vector = 500\n",
    "        image_folder         = None\n",
    "        if visulisation:\n",
    "            # save image_folder if passed as argument in visulisation - otherwise it stays None\n",
    "            try: \n",
    "                image_folder  = visulisation['image_folder']\n",
    "            except:\n",
    "                pass\n",
    "            number_randon_vector = visulisation['number_randon_vector']\n",
    "        \n",
    "        # for debugging\n",
    "        epoch_performance_image_save = 100\n",
    "        epoch_performance_quotient   = round(epoch_performance_image_save/epoch_performance_display)*epoch_performance_display\n",
    "\n",
    "        train_data_scaled = train_data\n",
    "        \n",
    "        self.train_data_scaled = train_data_scaled\n",
    "        \n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        history = []\n",
    "        self.random_vectors    = self.produce_random_vectors(number_randon_vector)\n",
    "        self.genenerated_batch = self.train_data_scaled[:len(self.random_vectors)]\n",
    "        if visulisation:\n",
    "            self.plot_data(0,self.train_data_scaled,self.genenerated_batch,image_folder)\n",
    "\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # Train Discriminator\n",
    "            # select random training examples for batch\n",
    "            batch_indexes = np.random.randint(0, train_data_scaled.shape[0], batch_size)\n",
    "            training_batch = train_data_scaled[batch_indexes]\n",
    "            \n",
    "            # generate artificial data\n",
    "            random_vectors    = self.produce_random_vectors(batch_size)\n",
    "            genenerated_batch = self.generator_model.predict(random_vectors)\n",
    "\n",
    "            # calculate loss\n",
    "            loss_real = self.discriminator_model.train_on_batch(training_batch, real)\n",
    "            loss_fake = self.discriminator_model.train_on_batch(genenerated_batch, fake)\n",
    "\n",
    "            # calculate mean loss\n",
    "            discriminator_loss = 0.5 * np.add(loss_real, loss_fake)\n",
    "\n",
    "            #  Train Generator\n",
    "            random_vectors    = self.produce_random_vectors(batch_size)\n",
    "            generator_loss    = self.gan.train_on_batch(random_vectors, real)\n",
    "\n",
    "            # keep history for plotting later\n",
    "            history.append({\"D\":discriminator_loss[0],\"G\":generator_loss})\n",
    "\n",
    "\n",
    "            # Plot the progress each epoch_performance_display time\n",
    "            if epoch % epoch_performance_display == 0:\n",
    "                print (\"---------------------------------------------------------\")\n",
    "                print (\"******************Epoch {}***************************\".format(epoch))\n",
    "                print (\"Discriminator loss: {} ({},{})\".format(discriminator_loss[0],loss_real,loss_fake))\n",
    "                print (\"Generator loss: {}\".format(generator_loss))\n",
    "                # print ('Noise epoch {}: <<{}>>'.format(epoch,random_vectors[0]))\n",
    "                print (\"---------------------------------------------------------\")\n",
    "                self.genenerated_batch = self.generator_model.predict(self.random_vectors)\n",
    "                if visulisation:\n",
    "                    if epoch % epoch_performance_quotient == 0:\n",
    "                        self.plot_data(epoch,train_data_scaled,genenerated_batch,image_folder)\n",
    "                    else:\n",
    "                        self.plot_data(epoch,train_data_scaled,genenerated_batch,None)\n",
    "        \n",
    "        # plots loss if requested\n",
    "        if visulisation:\n",
    "            self.plot_loss(history,image_folder)\n",
    "        else:\n",
    "            self.plot_loss(history)\n",
    "        plt.show()         \n",
    "\n",
    "    def prepare_plot(self):\n",
    "        # definitions for the axes\n",
    "        left, width = -1, 3\n",
    "        bottom, height = -1, 3\n",
    "        bottom_h = left_h = left + width + 0.02\n",
    "        rect_scatter = [left, bottom, width, height]\n",
    "        \n",
    "        fig = plt.figure(1, figsize=(8, 8))\n",
    "        axScatter = plt.axes(rect_scatter)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def plot_data(self,epoch,train_data,generated_data,image_folder=None):\n",
    "        \n",
    "        data_x = train_data[:,0].tolist()+generated_data[:,0].tolist()\n",
    "        data_y = train_data[:,1].tolist()+generated_data[:,1].tolist()\n",
    "        data_c = ['R']*len(train_data[:,0])+['P']*len(generated_data[:,0])\n",
    "        \n",
    "        df = pd.DataFrame(dict(data_x=data_x, data_y=data_y, data_c=data_c))\n",
    "        \n",
    "        if not self.ploted:\n",
    "            self.prepare_plot()\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim(-1, +1)\n",
    "            axes.set_ylim(-1, +1)\n",
    "            self.ploted = seaborn.scatterplot('data_x', 'data_y', data=df, hue='data_c',legend=False)\n",
    "\n",
    "            plt.ion()\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.clf()\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim(-1, +1)\n",
    "            axes.set_ylim(-1, +1)\n",
    "\n",
    "            self.ploted = seaborn.scatterplot('data_x', 'data_y', data=df, hue='data_c',legend=False)\n",
    "            plt.text(-0.9,0.9,str.zfill('{}'.format(epoch),6),bbox={'facecolor':'plum','pad':5,'edgecolor':'black'})\n",
    "            plt.draw()\n",
    "            plt.pause(0.001)\n",
    "\n",
    "\n",
    "            \n",
    "        if image_folder != None:\n",
    "            if not os.path.exists(image_folder):\n",
    "                os.mkdir(image_folder)\n",
    "            plt.savefig('{}/perform_{}.png'.format(image_folder,str.zfill('{}'.format(epoch),6)))\n",
    "\n",
    "               \n",
    "            \n",
    "        \n",
    "    def plot_loss(self, history,image_folder=None):\n",
    "        hist = pd.DataFrame(history)\n",
    "        plt.figure(figsize=(20,5))\n",
    "        for colnm in hist.columns:\n",
    "            plt.plot(hist[colnm],label=colnm)\n",
    "        plt.legend()\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.xlabel(\"epochs\")\n",
    "        if image_folder != None:\n",
    "            if not os.path.exists(image_folder):\n",
    "                os.mkdir(image_folder)\n",
    "            plt.savefig('{}/errors.png'.format(image_folder))\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def produce_random_vectors(self, size):\n",
    "        noise = np.random.normal(0, 1, (size, self.generator_input_dim))\n",
    "        return noise\n",
    "        # return self.generator_model.predict(noise)\n",
    "        \n",
    "    def build_generator_model(self,deep_generator_shape=[8,8]):\n",
    "        generator_input   = Input(shape=(self.generator_input_dim,))\n",
    "\n",
    "        deep_sequence_begin   = [Dense(deep_generator_shape[0], input_dim=self.generator_input_dim),LeakyReLU(alpha=0.2),]\n",
    "        deep_sequence_middle  = reduce((lambda x, y: x + y), [[Dense(num_nodes),LeakyReLU(alpha=0.2),BatchNormalization(momentum=0.2)] for num_nodes in deep_generator_shape[1:]])\n",
    "        deep_sequence_end     = [Dense(np.prod(self.input_shape), activation='tanh'),Reshape(self.input_shape)]\n",
    "        deep_sequence         = deep_sequence_begin+deep_sequence_middle+deep_sequence_end\n",
    "        generator_seqence     = Sequential(deep_sequence)\n",
    "\n",
    "        generator_output_tensor = generator_seqence(generator_input)       \n",
    "        generator_model = Model(generator_input, generator_output_tensor)\n",
    "\n",
    "        return generator_model\n",
    "\n",
    "\n",
    "    def build_discriminator_model(self):\n",
    "        discriminator_input = Input(shape=self.input_shape)\n",
    "        discriminator_sequence = Sequential([\n",
    "            Flatten(input_shape=self.input_shape),\n",
    "            # Dense(8,activation='tanh'),\n",
    "            Dense(8),\n",
    "            LeakyReLU(alpha=0.2),\n",
    "            Dense(8),\n",
    "            LeakyReLU(alpha=0.2),\n",
    "            Dense(2),\n",
    "            Dense(1)\n",
    "            ])\n",
    "    \n",
    "        discriminator_output_tensor = discriminator_sequence(discriminator_input)\n",
    "        discriminator_model         = Model(discriminator_input, discriminator_output_tensor)\n",
    "        return discriminator_model\n",
    "\n",
    "    def build_and_compile_gan(self):\n",
    "        real_input = Input(shape=(self.generator_input_dim,))\n",
    "\n",
    "        generator_output = self.generator_model(real_input)\n",
    "\n",
    "        # compile the discriminator model\n",
    "        self.discriminator_model.compile(loss='binary_crossentropy',optimizer=self.optimizer,metrics=self.metrics)\n",
    "        self.discriminator_model.trainable = False\n",
    "        \n",
    "        discriminator_output = self.discriminator_model(generator_output)        \n",
    "        \n",
    "        gan = Model(real_input, discriminator_output)\n",
    "        gan.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "\n",
    "        return gan\n",
    "        \n",
    "    \n",
    "    def compile_models(self):\n",
    "        self.discriminator_model.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "        self.discriminator_model.trainable = False\n",
    "\n",
    "        \n",
    "    def __str__(self):\n",
    "        return_string = '{}'.format(self.generator_model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating artifical data\n",
    "\n",
    "We start by creating artifical data following the simple function \n",
    "\n",
    "$f(x) = (x \\cdot \\epsilon) ^ 2$\n",
    "\n",
    "Where $\\epsilon$ is a random error for each example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "percentage_error   = 0.5\n",
    "input_values     = np.random.normal(0, 1, (100, 1))\n",
    "input_data       = [[x[0],np.square(x[0])*(1+np.random.rand()*percentage_error)] for x in input_values]\n",
    "\n",
    "input_data_train = np.array(input_data)\n",
    "input_data_shape = input_data_train[0].shape\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and plotting the GAN\n",
    "\n",
    "Next we set up the GAN and use 500 generated examples during training. \n",
    "The GAN will run for 2000 epochs - each time generating new data and trying to learn the discriminator. \n",
    "\n",
    "The construct 'visulisation_details' can also take in an 'image_folder'. If this information is given, the resulting plots are saved in this folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_g = simple_gan(input_data_shape,(2,1),10,deep_generator_shape=[8,8])\n",
    "visulisation_details={'number_randon_vector':500}\n",
    "#visulisation_details={'image_folder':'./examples','number_randon_vector':500}\n",
    "simple_g.train(2000,input_data_train,batch_size=256,visulisation=visulisation_details)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
