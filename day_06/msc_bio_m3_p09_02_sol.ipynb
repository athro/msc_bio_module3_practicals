{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Practical 2\n",
    "\n",
    "After having trained and used your first neural network, you should be able to apply these skills to another data set. \n",
    "\n",
    "The dataset used in this exercise is from the UCI machine learning repository. It consists of measurements of fetal heart rate (FHR) and uterine contraction (UC) features on cardiotocograms classified by expert obstetricians.\n",
    "\n",
    "A more detailed description can be found here: https://archive.ics.uci.edu/ml/datasets/Cardiotocography\n",
    "\n",
    "We have already extracted the main data table and the csv file can be found in the data subdirectory. For reference, the original Excel file is also supplied. \n",
    "\n",
    "The task is to classify the dataset based on the measurements. Here, we use the setting having three classes (according to the NSP column):\n",
    "\n",
    "Normal     = 1\n",
    "Suspect    = 2\n",
    "Pathologic = 3\n",
    "\n",
    "Feel free to use the 10 class version using the CLASS column. \n",
    "\n",
    "Your task in this exercise is to load the data and train a simple neural network to either predict the three classes or later 10 classes. \n",
    "\n",
    "For training purposes it is acceptable to use a train-test split. \n",
    "(However, you might want to evaluate the performance using a 5-fold cross validation. As the presented approach uses the keras module of tensorflow, the GridSearch of sklearn cannot easiliy be applied)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required imports\n",
    "\n",
    "Please note this practical also switched off some warnings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "from tensorflow.python import keras\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data \n",
    "\n",
    "This file contains a not very biological dataset. It is comprised of customers and their shopping behavious. I chose this one, to indicate a bit of pre-processing. A task which will potentially be required by the task for next week. \n",
    "\n",
    "A more detailed introduction in data wrangling will be introduced in another lecture. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/CTG.csv')\n",
    "# drop unused information\n",
    "df = df.drop(['b', 'e', 'Unnamed: 9', 'Unnamed: 31','Unnamed: 42','Unnamed: 44','A','B','C','D','E','AD','DE','LD','FS','SUSP'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>DR</th>\n",
       "      <th>LB</th>\n",
       "      <th>AC.1</th>\n",
       "      <th>FM.1</th>\n",
       "      <th>...</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>2128.000000</td>\n",
       "      <td>2128.000000</td>\n",
       "      <td>2128.000000</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.722484</td>\n",
       "      <td>7.503056</td>\n",
       "      <td>3.669017</td>\n",
       "      <td>1.576128</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.303857</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.009702</td>\n",
       "      <td>...</td>\n",
       "      <td>164.025400</td>\n",
       "      <td>4.068203</td>\n",
       "      <td>0.323612</td>\n",
       "      <td>137.452023</td>\n",
       "      <td>134.610536</td>\n",
       "      <td>138.090310</td>\n",
       "      <td>18.808090</td>\n",
       "      <td>0.320320</td>\n",
       "      <td>4.509878</td>\n",
       "      <td>1.304327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.560850</td>\n",
       "      <td>39.030452</td>\n",
       "      <td>2.877148</td>\n",
       "      <td>2.517794</td>\n",
       "      <td>0.061213</td>\n",
       "      <td>0.471687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.840844</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.047762</td>\n",
       "      <td>...</td>\n",
       "      <td>17.944183</td>\n",
       "      <td>2.949386</td>\n",
       "      <td>0.706059</td>\n",
       "      <td>16.381289</td>\n",
       "      <td>15.593596</td>\n",
       "      <td>14.466589</td>\n",
       "      <td>28.977636</td>\n",
       "      <td>0.610829</td>\n",
       "      <td>3.026883</td>\n",
       "      <td>0.614377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>...</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>...</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AC           FM           UC           DL           DS  \\\n",
       "count  2126.000000  2127.000000  2127.000000  2128.000000  2128.000000   \n",
       "mean      2.722484     7.503056     3.669017     1.576128     0.003759   \n",
       "std       3.560850    39.030452     2.877148     2.517794     0.061213   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     3.000000     0.000000     0.000000   \n",
       "75%       4.000000     2.000000     5.000000     3.000000     0.000000   \n",
       "max      26.000000   564.000000    23.000000    16.000000     1.000000   \n",
       "\n",
       "                DP      DR           LB         AC.1         FM.1  ...  \\\n",
       "count  2128.000000  2128.0  2126.000000  2126.000000  2127.000000  ...   \n",
       "mean      0.127820     0.0   133.303857     0.003178     0.009702  ...   \n",
       "std       0.471687     0.0     9.840844     0.003866     0.047762  ...   \n",
       "min       0.000000     0.0   106.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.0   126.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.0   133.000000     0.002000     0.000000  ...   \n",
       "75%       0.000000     0.0   140.000000     0.006000     0.003000  ...   \n",
       "max       4.000000     0.0   160.000000     0.019000     0.481000  ...   \n",
       "\n",
       "               Max         Nmax       Nzeros         Mode         Mean  \\\n",
       "count  2126.000000  2126.000000  2126.000000  2126.000000  2126.000000   \n",
       "mean    164.025400     4.068203     0.323612   137.452023   134.610536   \n",
       "std      17.944183     2.949386     0.706059    16.381289    15.593596   \n",
       "min     122.000000     0.000000     0.000000    60.000000    73.000000   \n",
       "25%     152.000000     2.000000     0.000000   129.000000   125.000000   \n",
       "50%     162.000000     3.000000     0.000000   139.000000   136.000000   \n",
       "75%     174.000000     6.000000     0.000000   148.000000   145.000000   \n",
       "max     238.000000    18.000000    10.000000   187.000000   182.000000   \n",
       "\n",
       "            Median     Variance     Tendency        CLASS          NSP  \n",
       "count  2126.000000  2126.000000  2126.000000  2126.000000  2126.000000  \n",
       "mean    138.090310    18.808090     0.320320     4.509878     1.304327  \n",
       "std      14.466589    28.977636     0.610829     3.026883     0.614377  \n",
       "min      77.000000     0.000000    -1.000000     1.000000     1.000000  \n",
       "25%     129.000000     2.000000     0.000000     2.000000     1.000000  \n",
       "50%     139.000000     7.000000     0.000000     4.000000     1.000000  \n",
       "75%     148.000000    24.000000     1.000000     7.000000     1.000000  \n",
       "max     186.000000   269.000000     1.000000    10.000000     3.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'DR', 'LB', 'AC.1', 'FM.1',\n",
       "       'UC.1', 'DL.1', 'DS.1', 'DP.1', 'ASTV', 'MSTV', 'ALTV', 'MLTV',\n",
       "       'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean', 'Median',\n",
       "       'Variance', 'Tendency', 'CLASS', 'NSP'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the CLASS attribute\n",
    "\n",
    "The column CLASS contains more detailed classification, when compared to NSP. Hence, we do not want to use it for learning and the column is removed. The results is saved in a new dataframe called df_new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop(['CLASS'],axis=1)\n",
    "df_new = df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On your own\n",
    "\n",
    "From here on, please use the skills you have learned so far to:\n",
    "\n",
    "1. Split the data into X and y\n",
    "2. Split the result into training and test (or even a 5-fold cross validation)\n",
    "3. Apply scaling for numerical variables and an appropriate encoding for cetegorical ones\n",
    "4. Set up a (multi-)layer neural network\n",
    "5. Train the network and report on its performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new[['AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'DR', 'LB', 'AC.1', 'FM.1', 'UC.1', 'DL.1', 'DS.1', 'DP.1', 'ASTV', 'MSTV', 'ALTV', 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean', 'Median', 'Variance', 'Tendency']]\n",
    "y = df_new['NSP']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split the result into training and test (or even a 5-fold cross validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Apply scaling for numerical variables and an appropriate encoding for cetegorical ones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder_labels = OneHotEncoder()\n",
    "\n",
    "onehotencoder_labels.fit(np.array([y_train]).transpose()) \n",
    "\n",
    "# ecode using the new representation\n",
    "y2_train = onehotencoder_labels.transform(np.array(np.array([y_train]).transpose())).toarray()\n",
    "y2_test = onehotencoder_labels.transform(np.array(np.array([y_test]).transpose())).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Set up a (multi-)layer neural network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Initializing Neural Network\n",
    "neural_network = Sequential()\n",
    "neural_network.add(Dense(activation = 'relu', input_dim = 28, units=10))\n",
    "neural_network.add(Dense(activation = 'relu', units=10))\n",
    "neural_network.add(Dense(activation = 'sigmoid', units=6))\n",
    "neural_network.add(Dense(activation = 'softmax', units=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Train the network and report on its performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1488/1488 [==============================] - 0s 267us/sample - loss: 0.5452 - acc: 0.7392\n",
      "Epoch 2/10\n",
      "1488/1488 [==============================] - 0s 110us/sample - loss: 0.3585 - acc: 0.8537\n",
      "Epoch 3/10\n",
      "1488/1488 [==============================] - 0s 117us/sample - loss: 0.2847 - acc: 0.8860\n",
      "Epoch 4/10\n",
      "1488/1488 [==============================] - 0s 129us/sample - loss: 0.2511 - acc: 0.8920\n",
      "Epoch 5/10\n",
      "1488/1488 [==============================] - 0s 124us/sample - loss: 0.2349 - acc: 0.8911\n",
      "Epoch 6/10\n",
      "1488/1488 [==============================] - 0s 116us/sample - loss: 0.2234 - acc: 0.8976\n",
      "Epoch 7/10\n",
      "1488/1488 [==============================] - 0s 114us/sample - loss: 0.2143 - acc: 0.9034\n",
      "Epoch 8/10\n",
      "1488/1488 [==============================] - 0s 116us/sample - loss: 0.2062 - acc: 0.9108\n",
      "Epoch 9/10\n",
      "1488/1488 [==============================] - 0s 146us/sample - loss: 0.1995 - acc: 0.9111\n",
      "Epoch 10/10\n",
      "1488/1488 [==============================] - 0s 127us/sample - loss: 0.1929 - acc: 0.9120\n"
     ]
    }
   ],
   "source": [
    "neural_network.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "neural_network.fit(X_train, y2_train, batch_size = 10, nb_epoch = 10)\n",
    "y_pred = neural_network.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the reverse of the OneHotEncoder to map back into numerical classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[486,  26,   1],\n",
       "       [ 23,  56,   0],\n",
       "       [  5,  17,  24]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = onehotencoder_labels.inverse_transform(y_pred)\n",
    "confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a report on the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.95      0.95      0.95       513\n",
      "     Suspect       0.57      0.71      0.63        79\n",
      "  Pathologic       0.96      0.52      0.68        46\n",
      "\n",
      "    accuracy                           0.89       638\n",
      "   macro avg       0.82      0.73      0.75       638\n",
      "weighted avg       0.90      0.89      0.89       638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['Normal','Suspect','Pathologic']\n",
    "print(classification_report(y_test,y_test_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
